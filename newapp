import streamlit as st
import whisper
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import ssl

# ä¿®å¤ SSL è¯ä¹¦é”™è¯¯ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®æ›´æ–°æ ¹è¯ä¹¦ï¼‰
ssl._create_default_https_context = ssl._create_unverified_context

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(page_title="ChatPPT Assistant", layout="wide")
st.title("ğŸ¤ ChatPPT Assistant: Voice & Text Interaction")

# åˆå§‹åŒ–èŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("Settings")
    input_mode = st.radio("Input Mode", ["Text", "Voice"])

# --- æ¨¡å‹åŠ è½½ï¼ˆç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼‰---
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")  # å¯é€‰ "small", "medium"

@st.cache_resource
def load_minicpm_model():
    model_name = "openbmb/MiniCPM-2B-dpo-fp16"
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)  # å…³é”®ä¿®å¤
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        trust_remote_code=True,
        torch_dtype=torch.float16  # åŠç²¾åº¦èŠ‚çœæ˜¾å­˜
    )
    return model, tokenizer

# åŠ è½½æ¨¡å‹ï¼ˆå¸¦è¿›åº¦æç¤ºï¼‰
with st.spinner("Loading models..."):
    try:
        whisper_model = load_whisper_model()
        minicpm_model, minicpm_tokenizer = load_minicpm_model()
    except Exception as e:
        st.error(f"Model loading failed: {str(e)}")
        st.stop()

# --- åŠŸèƒ½å‡½æ•° ---
def transcribe_audio(audio_path):
    result = whisper_model.transcribe(audio_path)
    return result["text"]

def generate_text(prompt):
    inputs = minicpm_tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = minicpm_model.generate(**inputs, max_length=200)
    return minicpm_tokenizer.decode(outputs[0], skip_special_tokens=True)

# --- ä¸»äº¤äº’ç•Œé¢ ---
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è¾“å…¥å¤„ç†
if input_mode == "Voice":
    uploaded_audio = st.file_uploader("Upload Audio (MP3/WAV)", type=["wav", "mp3"])
    if uploaded_audio:
        with st.spinner("Transcribing..."):
            text = transcribe_audio(uploaded_audio.name)
            st.session_state.messages.append({"role": "user", "content": text})
            with st.chat_message("user"):
                st.markdown(text)
else:
    if prompt := st.chat_input("Type your question..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

# ç”Ÿæˆå›å¤
if st.session_state.messages and st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Generating..."):
            try:
                full_response = generate_text(st.session_state.messages[-1]["content"])
                st.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"Generation failed: {str(e)}")
