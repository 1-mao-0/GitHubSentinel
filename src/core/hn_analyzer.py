import requests
from datetime import datetime, timedelta
from typing import List, Dict
from core.llm import LLMAnalyzer  # å¤ç”¨åŸæœ‰LLM

class HNAnalyzer:
    HN_API = "https://hn.algolia.com/api/v1/search"

    def __init__(self):
        self.llm = LLMAnalyzer()
        self.system_prompt = """
        # Role: Hacker News è¶‹åŠ¿åˆ†æå¸ˆ
        è¾“å‡ºè¦æ±‚ï¼š
        1. æŒ‰æŠ€æœ¯é¢†åŸŸåˆ†ç±»ï¼ˆAI/åŒºå—é“¾/å®‰å…¨ç­‰ï¼‰
        2. æ ‡æ³¨çƒ­åº¦æŒ‡æ ‡ï¼ˆğŸ”¥xNï¼‰
        3. åŒ…å«ä¸“å®¶çŸ­è¯„
        """

    def fetch_top_stories(self, hours: int = 24) -> List[Dict]:
        """è·å–æœ€è¿‘Nå°æ—¶çš„çƒ­é—¨æ•…äº‹"""
        params = {
            "tags": "story",
            "numericFilters": f"created_at_i>{int((datetime.now() - timedelta(hours=hours)).timestamp()}",
            "hitsPerPage": 50
        }
        resp = requests.get(self.HN_API, params=params)
        return sorted(resp.json()["hits"], key=lambda x: -x["points"])

    def generate_daily_report(self) -> str:
        """ç”Ÿæˆæ¯æ—¥è¶‹åŠ¿æŠ¥å‘Š"""
        stories = self.fetch_top_stories()
        report = self.llm.analyze(
            system_prompt=self.system_prompt,
            user_content="åˆ†æä»¥ä¸‹HNæ•…äº‹è¶‹åŠ¿ï¼š\n" + "\n".join(
                f"- {s['title']} (ğŸ”¥{s['points']})" 
                for s in stories[:10]
            )
        )
        return f"# Hacker News æ¯æ—¥æŠ¥å‘Š\n{report}"
